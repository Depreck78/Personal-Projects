{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1227e75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Country: Indonesia - Political Articles\n",
      "\n",
      "--- Article ---\n",
      "Title: Indonesia's Social Media E-Commerce Ban\n",
      "Found Keywords: regulations\n",
      "Average Scores: {'relevancy': 4.0, 'sentiment': -3.0, 'geographical': 4.0, 'frequency': 1.0}, Impact Score: 3.0\n",
      "-------------------\n",
      "\n",
      "--- Article ---\n",
      "Title: Indonesia Visa Requirements 2024 - Secret Retreats\n",
      "Found Keywords: visa\n",
      "Average Scores: {'relevancy': 5.0, 'sentiment': -4.0, 'geographical': 5.0, 'frequency': 2.0}, Impact Score: 4.0\n",
      "-------------------\n",
      "\n",
      "--- Article ---\n",
      "Title: Indonesia’s New E-commerce Regulations Take a Bite Out of TikTok’s Market Share\n",
      "Found Keywords: election, policy, regulations\n",
      "Average Scores: {'relevancy': 3.67, 'sentiment': 1.33, 'geographical': 4.33, 'frequency': 1.67}, Impact Score: 3.22\n",
      "-------------------\n",
      "\n",
      "--- Article ---\n",
      "Title: Amendment to Indonesian Visa Laws: | Bagus Enrico & Partners\n",
      "Found Keywords: policy, visa, regulations\n",
      "Average Scores: {'relevancy': 4.33, 'sentiment': -1.0, 'geographical': 4.33, 'frequency': 2.0}, Impact Score: 3.55\n",
      "-------------------\n",
      "\n",
      "--- Article ---\n",
      "Title: Indonesian Travel Startup Considers $2 Billion SPAC Deal\n",
      "Found Keywords: election, policy\n",
      "Average Scores: {'relevancy': 3.5, 'sentiment': 3.5, 'geographical': 4.5, 'frequency': 2.0}, Impact Score: 3.33\n",
      "-------------------\n",
      "\n",
      "Country: Malaysia - Political Articles\n",
      "\n",
      "Country: Singapore - Political Articles\n",
      "\n",
      "Country: Indonesia - Competitor Articles\n",
      "\n",
      "--- Article ---\n",
      "Title: Traveling to Indonesia in 2024: Documentation and Procedures ✈️\n",
      "Found Keywords: None\n",
      "Average Scores: {'relevancy': 0, 'sentiment': 0, 'geographical': 0, 'frequency': 0}, Impact Score: 0\n",
      "-------------------\n",
      "\n",
      "--- Article ---\n",
      "Title: A Glimpse Of The Battle Of Online Travel Giants In Indonesia | by Groundhog Technologies Mobility Intelligence | Medium\n",
      "Found Keywords: market share, agoda, traveloka, booking.com\n",
      "Average Scores: {'relevancy': 4.5, 'sentiment': -4.25, 'geographical': 5.0, 'frequency': 1.5}, Impact Score: 3.67\n",
      "-------------------\n",
      "\n",
      "--- Article ---\n",
      "Title: Indonesia: Which online travel agencies are best at turning awareness to purchase intent in Q1 2024?\n",
      "Found Keywords: market share, traveloka\n",
      "Average Scores: {'relevancy': 4.5, 'sentiment': -4.0, 'geographical': 5.0, 'frequency': 1.0}, Impact Score: 3.5\n",
      "-------------------\n",
      "\n",
      "--- Article ---\n",
      "Title: Anya Geraldine Promotes a ‘Happy Wallet’ in New Agoda Campaign » Agoda: See The World For Less\n",
      "Found Keywords: agoda\n",
      "Average Scores: {'relevancy': 4.0, 'sentiment': -4.0, 'geographical': 5.0, 'frequency': 2.0}, Impact Score: 3.67\n",
      "-------------------\n",
      "\n",
      "Country: Malaysia - Competitor Articles\n",
      "\n",
      "Country: Singapore - Competitor Articles\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "\n",
    "def clean_file(file_path):\n",
    "    try:\n",
    "        # Try to read the file.\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            news_article = file.read()\n",
    "    # If file is not found.\n",
    "    except FileNotFoundError:\n",
    "        print(f\"No File: {file_path}\")\n",
    "        return None\n",
    "    # IF file exist but can not read the file.\n",
    "    except Exception:\n",
    "        print(f\"File Error {file_path}: {Exception}\")\n",
    "        return None\n",
    "\n",
    "    # Parse the HTML content.\n",
    "    sp = bs(news_article, \"html.parser\")\n",
    "\n",
    "    # Get the title.\n",
    "    title = sp.find(\"title\").get_text(strip = True) \\\n",
    "        if sp.find(\"title\") else \"No Title\" # If title is not found.\n",
    "\n",
    "    # Get the publication date.\n",
    "    date = None\n",
    "    for date_tag in [\"meta\", \"time\"]:\n",
    "        date_element = sp.find(date_tag, {\"name\": \"pubdate\"}) or sp.find(date_tag, {\"property\": \"article:published_time\"})\n",
    "        if date_element:\n",
    "            date = date_element.get(\"content\", \"\").strip()\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "    date = date or \"No Date Found\" # If date is not found.\n",
    "\n",
    "    # Locate the main content container.\n",
    "    main_content = None\n",
    "    # For loop to check the following classes.\n",
    "    for container_class in [\"article-section\", \"main-content\", \"article-body\", \"content\", \"post-content\", \"Page-content\", \"col-xs-12 tjpcontainer\"]:\n",
    "        # Search in div classes.\n",
    "        main_content = sp.find(\"div\", {\"class\": container_class})\n",
    "        if main_content:\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    if not main_content:\n",
    "        main_content = sp\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # Remove unwanted elements\n",
    "    for unwanted in main_content.find_all([\"header\", \"footer\", \"nav\", \"aside\", \"button\", \"script\", \"style\", \"svg\"]):\n",
    "        unwanted.decompose()\n",
    "\n",
    "    # Extract and clean the article body\n",
    "    article_body = []\n",
    "    for tag in main_content.find_all([\"p\", \"div\"]):\n",
    "        if not any(cls in tag.attrs.get(\"class\", []) for cls in [\"ad\", \"sponsored\", \"footer\", \"Page-footer-bottom\", \"header\", \"nav\", \"sidebar\", \"copyright\", \"feedback\", \"col-xs-12 footer\"]):\n",
    "            text = tag.get_text(strip=True)\n",
    "            if text:\n",
    "                article_body.append(text)\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    # Combine paragraphs into the cleaned content\n",
    "    cleaned_content = \"\\n\".join(article_body)\n",
    "\n",
    "    # Verify that the cleaned content is not empty\n",
    "    if not cleaned_content.strip():\n",
    "        return None\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return {\"title\": title, \"date\": date, \"content\": cleaned_content}\n",
    "\n",
    "def process_files(file_paths):\n",
    "    cleaned_articles = [] # Empty list for clean articles\n",
    "    for file_path in file_paths: # Goes through each file in the list of news.\n",
    "        article = clean_file(file_path)\n",
    "        if article: # If article is cleaned then append to clean list.\n",
    "            cleaned_articles.append(article)\n",
    "        else:\n",
    "            pass\n",
    "    return cleaned_articles\n",
    "\n",
    "def match_keywords(content, keywords):\n",
    "    for keyword in keywords:\n",
    "        # Search and match keywords.\n",
    "        if re.search(rf'\\b{re.escape(keyword)}\\b', content, re.IGNORECASE):\n",
    "            return keyword\n",
    "        else:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "def group_articles_by_country(cleaned_articles, country_mapping):\n",
    "    grouped_articles = {country: [] for country in country_mapping} # Country with the keywords that map each country.\n",
    "\n",
    "    for article in cleaned_articles: # Go through each article.\n",
    "        article_content = article.get(\"content\", \"\").lower() # Get conetent in lowercase.\n",
    "\n",
    "        for country, keywords in country_mapping.items(): # If a keyword is found in the content then append to the corresponding country.\n",
    "            if any(keyword.lower() in article_content for keyword in keywords):\n",
    "                grouped_articles[country].append(article)\n",
    "                break\n",
    "            else:\n",
    "                # Articles that do not match any country.\n",
    "                grouped_articles.setdefault(\"Unknown\", []).append(article)\n",
    "\n",
    "    return grouped_articles\n",
    "\n",
    "def categorize_articles_by_type(grouped_articles, category_keywords):\n",
    "\n",
    "    categorized_articles = {} # Empty dictionary to story article based on category.\n",
    "\n",
    "    for country, articles in grouped_articles.items(): # Goes through the articles in each country.\n",
    "        categorized_articles[country] = {\"political\": [], \"competitor\": [], \"uncategorized\": []} # Empty categories for each country.\n",
    "\n",
    "        # Go through each article.\n",
    "        for article in articles:\n",
    "            article_content = article.get(\"content\", \"\").lower() # Get the content in lowercase.\n",
    "\n",
    "            # Match political keywords.\n",
    "            matched_keyword = match_keywords(article_content, category_keywords[\"political\"])\n",
    "            if matched_keyword: # If it's matched then append article to political category.\n",
    "                categorized_articles[country][\"political\"].append(article)\n",
    "                continue\n",
    "\n",
    "            # Match competitor keywords.\n",
    "            matched_keyword = match_keywords(article_content, category_keywords[\"competitor\"])\n",
    "            if matched_keyword: # If it's matched then append article to competitor category.\n",
    "                categorized_articles[country][\"competitor\"].append(article)\n",
    "                continue\n",
    "\n",
    "            # If no match, add to uncategorized.\n",
    "            categorized_articles[country][\"uncategorized\"].append(article)\n",
    "\n",
    "    return categorized_articles\n",
    "\n",
    "\n",
    "def analyze_political_articles(categorized_articles, political_keywords):\n",
    "    \n",
    "    for country, categories in categorized_articles.items(): # Checks each category in each country.\n",
    "        political_articles = categories.get(\"political\", []) # Checks for the political category.\n",
    "\n",
    "        print(f\"\\nCountry: {country} - Political Articles\") # Print country and category of news.\n",
    "        \n",
    "        for article in political_articles: # Goes through the political articles.\n",
    "            title = article.get(\"title\", \"No Title\") # Takes the title.\n",
    "            content = article.get(\"content\", \"\").lower() # Takes content all in lower case.\n",
    "            \n",
    "            # Combine title and content for analysis\n",
    "            combined_text = (title + \" \" + content).lower()\n",
    "            \n",
    "            # Track found keywords and their scores\n",
    "            found_keywords = [] # Empty list for found keywords.\n",
    "            total_scores = {'relevancy': 0, 'sentiment': 0, 'geographical': 0, 'frequency': 0} # Total scores.\n",
    "            count = 0\n",
    "            \n",
    "            for keyword, scores in political_keywords.items(): # Goes through the list of keywords.\n",
    "                # Checks if the keyword appears as a whole word within combined_text. \n",
    "                # The '\\b' ensures word boundaries, and 're.escape()' makes sure special characters in the keyword are treated literally.\n",
    "                if re.search(rf'\\b{re.escape(keyword)}\\b', combined_text, re.IGNORECASE): \n",
    "                    found_keywords.append(keyword) # If the keyword is found append.\n",
    "                    total_scores['relevancy'] += scores.get('relevancy', 0) # Add relevancy score.\n",
    "                    total_scores['sentiment'] += scores.get('sentiment', 0) # Add sentiment score.\n",
    "                    total_scores['geographical'] += scores.get('geographical', 0) # Add geographical score.\n",
    "                    total_scores['frequency'] += scores.get('frequency', 0) # Add frequency score.\n",
    "                    count += 1\n",
    "                else:\n",
    "                    pass\n",
    "            \n",
    "            impact_score = 0\n",
    "\n",
    "            if count > 0:\n",
    "                avg_scores = {x: round(y / count, 2) for x, y in total_scores.items()} # Take average scores.\n",
    "                impact_score = round((avg_scores[\"frequency\"] + avg_scores[\"geographical\"] + avg_scores[\"relevancy\"])/3, 2) # Formula for impact score.\n",
    "            else:\n",
    "                avg_scores = {'relevancy': 0, 'sentiment': 0, 'geographical': 0, 'frequency': 0} # Scores are 0.\n",
    "\n",
    "            # Print Analysis for political news.\n",
    "            print(\"\\n--- Article ---\")\n",
    "            print(f\"Title: {title}\")\n",
    "            print(f\"Found Keywords: {', '.join(found_keywords) if found_keywords else 'None'}\")\n",
    "            print(f\"Average Scores: {avg_scores}, Impact Score: {impact_score}\")\n",
    "            print(\"-------------------\")\n",
    "\n",
    "def analyze_competitor_articles(categorized_articles, competitor_keywords):\n",
    "    \n",
    "    for country, categories in categorized_articles.items(): # Checks each category in each country.\n",
    "        competitor_articles = categories.get(\"competitor\", []) # Checks for the competitor category.\n",
    "\n",
    "        print(f\"\\nCountry: {country} - Competitor Articles\") # Print country and category of news\n",
    "        \n",
    "        for article in competitor_articles: # Goes through every article in the competitor category.\n",
    "            title = article.get(\"title\", \"No Title\") # Get the title.\n",
    "            content = article.get(\"content\", \"\").lower() # get the content.\n",
    "            \n",
    "            combined_text = (title + \" \" + content).lower() # Combine title and content for analysis.\n",
    "            \n",
    "            found_keywords = [] # Empty list to collect keywords found in each article.\n",
    "            total_scores = {'relevancy': 0, 'sentiment': 0, 'geographical': 0, 'frequency': 0} # Total score.\n",
    "            count = 0 # Number of keywords found in each article.\n",
    "            \n",
    "            for keyword, scores in competitor_keywords.items(): # Goes through the list of keywords.\n",
    "                # Checks if the keyword appears as a whole word within combined_text. \n",
    "                # The '\\b' ensures word boundaries, and 're.escape()' makes sure special characters in the keyword are treated literally.\n",
    "                if re.search(rf'\\b{re.escape(keyword)}\\b', combined_text, re.IGNORECASE): \n",
    "                    found_keywords.append(keyword) # If the keyword is found append.\n",
    "                    total_scores['relevancy'] += scores.get('relevancy', 0) # Add relevancy score.\n",
    "                    total_scores['sentiment'] += scores.get('sentiment', 0) # Add sentiment score.\n",
    "                    total_scores['geographical'] += scores.get('geographical', 0) # Add geographical score.\n",
    "                    total_scores['frequency'] += scores.get('frequency', 0) # Add frequency score.\n",
    "                    count += 1 # Add 1 to count.\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "            impact_score = 0\n",
    "\n",
    "            if count > 0: \n",
    "                avg_scores = {x: round(y / count, 2) for x, y in total_scores.items()} # Takes the averages of each score.\n",
    "                impact_score = round((avg_scores[\"frequency\"] + avg_scores[\"geographical\"] + avg_scores[\"relevancy\"])/3, 2) # Formula for Impact score.\n",
    "            else:\n",
    "                avg_scores = {'relevancy': 0, 'sentiment': 0, 'geographical': 0, 'frequency': 0} # Scores are 0.\n",
    "\n",
    "            # Print analysis for competitor news.\n",
    "            print(\"\\n--- Article ---\")\n",
    "            print(f\"Title: {title}\")\n",
    "            print(f\"Found Keywords: {', '.join(found_keywords) if found_keywords else 'None'}\")\n",
    "            print(f\"Average Scores: {avg_scores}, Impact Score: {impact_score}\")\n",
    "            print(\"-------------------\")\n",
    "\n",
    "# Competitor Keywords.\n",
    "competitor_keywords = {\n",
    "    \"merger\": {'relevancy': 3, 'sentiment': -1, 'geographical': 5, 'frequency': 1},\n",
    "    \"acquisition\": {'relevancy': 4, 'sentiment': -3, 'geographical': 5, 'frequency': 1},\n",
    "    \"market share\": {'relevancy': 5, 'sentiment': -4, 'geographical': 5, 'frequency': 1},\n",
    "    \"funding\": {'relevancy': 4, 'sentiment': -5, 'geographical': 5, 'frequency': 1},\n",
    "    \"agoda\": {'relevancy': 4, 'sentiment': -4, 'geographical': 5, 'frequency': 2},\n",
    "    \"traveloka\": {'relevancy': 4, 'sentiment': -4, 'geographical': 5, 'frequency': 1},\n",
    "    \"booking.com\": {'relevancy': 5, 'sentiment': -5, 'geographical': 5, 'frequency': 2}\n",
    "}\n",
    "\n",
    "# Political Keywords.\n",
    "political_keywords = {\n",
    "    \"election\": {'relevancy': 3, 'sentiment': 3, 'geographical': 5, 'frequency': 1},\n",
    "    \"policy\": {'relevancy': 4, 'sentiment': 4, 'geographical': 4, 'frequency': 3},\n",
    "    \"visa\": {'relevancy': 5, 'sentiment': -4, 'geographical': 5, 'frequency': 2},\n",
    "    \"regulations\": {'relevancy': 4, 'sentiment': -3, 'geographical': 4, 'frequency': 1},\n",
    "    \"restrictions\": {'relevancy': 4, 'sentiment': -3, 'geographical': 5, 'frequency': 1}\n",
    "}\n",
    "\n",
    "# News files.\n",
    "file_paths = [\n",
    "    \"/Users/erickxu/Desktop/Indo_pnews1.html\",\n",
    "    \"/Users/erickxu/Desktop/Indo_pnews2.html\",\n",
    "    \"/Users/erickxu/Desktop/Indo_pnews3.html\",\n",
    "    \"/Users/erickxu/Desktop/Indo_pnews4.html\",\n",
    "    \"/Users/erickxu/Desktop/Indo_pnews5.html\",\n",
    "    \"/Users/erickxu/Desktop/Indo_cnews1.html\",\n",
    "    \"/Users/erickxu/Desktop/Indo_cnews2.html\",\n",
    "    \"/Users/erickxu/Desktop/Indo_cnews3.html\",\n",
    "    \"/Users/erickxu/Desktop/Indo_cnews4.html\",\n",
    "    \"/Users/erickxu/Desktop/Indo_cnews5.html\",\n",
    "]\n",
    "\n",
    "# Process all files.\n",
    "cleaned_articles = process_files(file_paths)\n",
    "\n",
    "# Group articles by country.\n",
    "country_mapping = {\n",
    "    \"Indonesia\": [\"jakarta\", \"indonesia\", \"java\", \"sumatra\"],\n",
    "    \"Malaysia\": [\"kuala lumpur\", \"malaysia\", \"sabah\", \"sarawak\"],\n",
    "    \"Singapore\": [\"singapore\"],\n",
    "}\n",
    "\n",
    "grouped_articles = group_articles_by_country(cleaned_articles, country_mapping)\n",
    "\n",
    "# Categorize articles.\n",
    "category_keywords = {\n",
    "    \"political\": [\"election\", \"government\", \"policy\", \"minister\", \"parliament\", \"law\"],\n",
    "    \"competitor\": [\n",
    "        \"brand\", \"merger\", \"market\", \"launched\", \"market share\", \"funding\", \"acquired\", \"business\", \"quarter\",\n",
    "        \"competitor\", \"rival\", \"company\", \"startup\", \"deal\", \"tiket.com\", \"traveloka\", \"booking.com\", \"agoda\",\n",
    "        \"trip.com\", \"acquisition\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "categorized_articles = categorize_articles_by_type(grouped_articles, category_keywords)\n",
    "\n",
    "# Call the functions with categorized articles and keywords.\n",
    "analyze_political_articles(categorized_articles, political_keywords)\n",
    "analyze_competitor_articles(categorized_articles, competitor_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6494502e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
